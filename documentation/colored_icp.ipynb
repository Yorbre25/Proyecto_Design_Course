{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Colored ICP registration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import open3d as o3d\n",
    "import numpy as np\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_pcds = o3d.data.DemoICPPointClouds()\n",
    "source = o3d.io.read_point_cloud(\"../output/cuadra/pcd/IMG_1701.ply\")\n",
    "target = o3d.io.read_point_cloud(\"../output/cuadra/pcd/IMG_1703.ply\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_registration_result(source, target, transformation):\n",
    "    source_temp = copy.deepcopy(source)\n",
    "    target_temp = copy.deepcopy(target)\n",
    "    # source_temp.paint_uniform_color([1, 0.706, 0])\n",
    "    # target_temp.paint_uniform_color([0, 0.651, 0.929])\n",
    "    source_temp.transform(transformation)\n",
    "    # o3d.visualization.draw_plotly([source_temp, target_temp])\n",
    "    o3d.visualization.draw_geometries([source_temp, target_temp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_init = np.eye(4) # identity matrix / no transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_registration_result(source, target, trans_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_point_cloud(pcd, voxel_size):\n",
    "    print(\":: Downsample with a voxel size %.3f.\" % voxel_size)\n",
    "    pcd_down = pcd.voxel_down_sample(voxel_size)\n",
    "\n",
    "    radius_normal = voxel_size * 2\n",
    "    print(\":: Estimate normal with search radius %.3f.\" % radius_normal) \n",
    "    #Noramls are used to calculate the FPFH features\n",
    "    pcd_down.estimate_normals(o3d.geometry.KDTreeSearchParamHybrid(radius=radius_normal, max_nn=30))\n",
    "    return pcd_down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: Downsample with a voxel size 0.050.\n",
      ":: Estimate normal with search radius 0.100.\n",
      ":: Downsample with a voxel size 0.050.\n",
      ":: Estimate normal with search radius 0.100.\n",
      "Source has 307200 points while source_down has 307200 points\n",
      "Target has 307200 points while target has 307200 points\n"
     ]
    }
   ],
   "source": [
    "voxel_size = 0.05\n",
    "source_down = preprocess_point_cloud(source, voxel_size)\n",
    "target_down = preprocess_point_cloud(target, voxel_size)\n",
    "print(\"Source has %d points while source_down has %d points\" % (len(source.points), len(source_down.points)))\n",
    "print(\"Target has %d points while target has %d points\" % (len(target.points), len(target_down.points)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw_registration_result(source_down, target_down, trans_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.05\n",
    "criteria = o3d.pipelines.registration.ICPConvergenceCriteria(max_iteration=100000)\n",
    "reg_p2pl = o3d.pipelines.registration.registration_colored_icp(\n",
    "    source_down, target_down, threshold, trans_init,\n",
    "    o3d.pipelines.registration.TransformationEstimationForColoredICP(),\n",
    "    criteria)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RegistrationResult with fitness=1.640625e-02, inlier_rmse=3.754085e-02, and correspondence_set size of 5040\n",
      "Access transformation to get result.\n",
      "[[ 9.99998685e-01 -1.62193542e-03 -2.47179785e-10 -3.07658809e-02]\n",
      " [ 1.62193542e-03  9.99998685e-01 -5.49142784e-10  6.85478647e-01]\n",
      " [ 2.48070134e-10  5.48741152e-10  1.00000000e+00  1.02051258e-08]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  1.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "print(reg_p2pl)\n",
    "print(reg_p2pl.transformation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_registration_result(source, target, reg_p2pl.transformation)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
